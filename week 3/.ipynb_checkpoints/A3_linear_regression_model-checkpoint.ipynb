{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ea0e97",
   "metadata": {},
   "source": [
    "### <div style=\"background: black; padding: 10px 250px\"><img src=\"https://www.veldikompetens.se/wp-content/themes/consid/static/icons/VeldiKompetens_Logo_Web_Negative.svg\" title=\"Veldi kompetens\" /></div>\n",
    "\n",
    "# Assignment 3\n",
    "\n",
    "Welcome to your machine learning assignment! In this assignment, you will dive deeper into the exciting world of classification tasks using a linear regression model classifier. We will be using Python and the scikit-learn library to perform these tasks.\n",
    "\n",
    "In this assignment I will use a *House Prices dataset*, split it into training and testing sets, create a linear regression model, train the model on the training set, make predictions on the testing set, and then evaluate the performance of the model using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE). \n",
    "\n",
    "After that, you will try to do the same thing with a database of used sold cars and train a model to make predictions of the cars prices.\n",
    "\n",
    "The House Prices dataset can be [found here](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ff2e5",
   "metadata": {},
   "source": [
    "## Part 1 - How it's done\n",
    "\n",
    "In this part I will demonstrate how to train a model on existing data by loading the dataset, splitting it into training and testing sets, create a classifier, train the model on the training set, make predictions on the testing set, and then evaluate the performance of the model using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b900ca",
   "metadata": {},
   "source": [
    "### 1. Import the required libraries\n",
    "\n",
    "First, I import the necessary libraries and modules that will be used in the code:\n",
    "\n",
    "- `LinearRegression` from `sklearn.linear_model` for implementing the linear regression model.\n",
    "- `mean_absolute_error` and `mean_squared_error` from `sklearn.metrics` for calculating the evaluation metrics.\n",
    "- `sqrt` from `math` to compute the square root.\n",
    "- `pandas` as pd for working with data in a tabular format.\n",
    "- `train_test_split` from `sklearn.model_selection` for splitting the dataset into training and testing sets.\n",
    "- `OneHotEncoder` from `sklearn.preprocessing` for handling other data types in our dataset, such as Neighborhood\n",
    "- `pyplot` from `matplotlib` to visualize the data and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d93909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761d7d0",
   "metadata": {},
   "source": [
    "### 2. Load and prepare the dataset\n",
    "\n",
    "To preprocess the dataset, I perform the following steps:\n",
    "\n",
    "- I specify a list of relevant features that will be used for the analysis. These features include, among others, 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', and 'YearBuilt'.\n",
    "- I select only the rows that have non-null values for the specified features and the target variable 'SalePrice'. This is done using the `dropna` function, which removes rows with missing values from the DataFrame. The resulting DataFrame will contain only the selected features and the target variable.\n",
    "- After preprocessing, I split the dataset into features (`X`) and the target variable (`y`) for further analysis. The features are extracted from the DataFrame df by selecting the columns specified in the features list. The target variable 'SalePrice' is extracted separately and assigned to the variable y.\n",
    "\n",
    "By performing these steps, the code loads the dataset, preprocesses it by selecting relevant features and removing rows with missing values, and then splits it into features (X) and the target variable (y) for further analysis or modeling tasks.\n",
    "\n",
    "#### Select features\n",
    "\n",
    "To determine which features are relevant to include in the model training data, we need to consider the nature of the problem and the information provided in the dataset. It is important to select features that have a potential impact on the target variable (SalePrice) and can contribute to the prediction of house prices.\n",
    "\n",
    "- OverallQual: Overall material and finish quality of the house\n",
    "- GrLivArea: Above ground living area in square feet\n",
    "- GarageCars: Size of garage in car capacity\n",
    "- TotalBsmtSF: Total basement area in square feet\n",
    "- FullBath: Number of full bathrooms\n",
    "- YearBuilt: Original construction year of the house\n",
    "- LotArea: Total lot size in square feet\n",
    "- Neighborhood: Descriptive location within the city or area\n",
    "- YearRemodAdd: Remodeling date (same as construction date if no remodeling or additions)\n",
    "- GarageArea: Size of garage in square feet\n",
    "- OverallCond: Overall condition rating of the house\n",
    "\n",
    "These features represent different aspects of the house that could influence its sale price, such as overall quality, size, amenities, and age.\n",
    "\n",
    "To find and select features, use the different functions for exploration that we have used previously, such as `df.head()`, `df.info()`, and `df.describe()`. You can also find information about the features (columns) in the dataset by visiting the source, in this case Kaggle.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163fe967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n",
      "None\n",
      "       OverallQual    GrLivArea   GarageCars  TotalBsmtSF     FullBath  \\\n",
      "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
      "mean      6.099315  1515.463699     1.767123  1057.429452     1.565068   \n",
      "std       1.382997   525.480383     0.747315   438.705324     0.550916   \n",
      "min       1.000000   334.000000     0.000000     0.000000     0.000000   \n",
      "25%       5.000000  1129.500000     1.000000   795.750000     1.000000   \n",
      "50%       6.000000  1464.000000     2.000000   991.500000     2.000000   \n",
      "75%       7.000000  1776.750000     2.000000  1298.250000     2.000000   \n",
      "max      10.000000  5642.000000     4.000000  6110.000000     3.000000   \n",
      "\n",
      "         YearBuilt        LotArea  YearRemodAdd   GarageArea  OverallCond  \\\n",
      "count  1460.000000    1460.000000   1460.000000  1460.000000  1460.000000   \n",
      "mean   1971.267808   10516.828082   1984.865753   472.980137     5.575342   \n",
      "std      30.202904    9981.264932     20.645407   213.804841     1.112799   \n",
      "min    1872.000000    1300.000000   1950.000000     0.000000     1.000000   \n",
      "25%    1954.000000    7553.500000   1967.000000   334.500000     5.000000   \n",
      "50%    1973.000000    9478.500000   1994.000000   480.000000     5.000000   \n",
      "75%    2000.000000   11601.500000   2004.000000   576.000000     6.000000   \n",
      "max    2010.000000  215245.000000   2010.000000  1418.000000     9.000000   \n",
      "\n",
      "           SalePrice  \n",
      "count    1460.000000  \n",
      "mean   180921.195890  \n",
      "std     79442.502883  \n",
      "min     34900.000000  \n",
      "25%    129975.000000  \n",
      "50%    163000.000000  \n",
      "75%    214000.000000  \n",
      "max    755000.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('A3_house_prices_train.csv')\n",
    "\n",
    "# Print available features (columns) and their data type\n",
    "print(df.info())\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Select relevant features\n",
    "features = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt', \n",
    "    'LotArea', 'YearRemodAdd', 'GarageArea', 'OverallCond', 'Neighborhood'\n",
    "]\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df[features + ['SalePrice']].dropna()\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e590590",
   "metadata": {},
   "source": [
    "### 3. Working with other data types\n",
    "\n",
    "To train the model on data like Neighborhood, which is a string instead of a number (float or int), we have to encode it using OneHotEncoder. Take a look at the columns by calling `df.info()` and `df.head()`, each 'Neighborhood'  value now has its own column, which is great for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a666e3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 36 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   OverallQual           1460 non-null   int64  \n",
      " 1   GrLivArea             1460 non-null   int64  \n",
      " 2   GarageCars            1460 non-null   int64  \n",
      " 3   TotalBsmtSF           1460 non-null   int64  \n",
      " 4   FullBath              1460 non-null   int64  \n",
      " 5   YearBuilt             1460 non-null   int64  \n",
      " 6   LotArea               1460 non-null   int64  \n",
      " 7   YearRemodAdd          1460 non-null   int64  \n",
      " 8   GarageArea            1460 non-null   int64  \n",
      " 9   OverallCond           1460 non-null   int64  \n",
      " 10  SalePrice             1460 non-null   int64  \n",
      " 11  Neighborhood_Blmngtn  1460 non-null   float64\n",
      " 12  Neighborhood_Blueste  1460 non-null   float64\n",
      " 13  Neighborhood_BrDale   1460 non-null   float64\n",
      " 14  Neighborhood_BrkSide  1460 non-null   float64\n",
      " 15  Neighborhood_ClearCr  1460 non-null   float64\n",
      " 16  Neighborhood_CollgCr  1460 non-null   float64\n",
      " 17  Neighborhood_Crawfor  1460 non-null   float64\n",
      " 18  Neighborhood_Edwards  1460 non-null   float64\n",
      " 19  Neighborhood_Gilbert  1460 non-null   float64\n",
      " 20  Neighborhood_IDOTRR   1460 non-null   float64\n",
      " 21  Neighborhood_MeadowV  1460 non-null   float64\n",
      " 22  Neighborhood_Mitchel  1460 non-null   float64\n",
      " 23  Neighborhood_NAmes    1460 non-null   float64\n",
      " 24  Neighborhood_NPkVill  1460 non-null   float64\n",
      " 25  Neighborhood_NWAmes   1460 non-null   float64\n",
      " 26  Neighborhood_NoRidge  1460 non-null   float64\n",
      " 27  Neighborhood_NridgHt  1460 non-null   float64\n",
      " 28  Neighborhood_OldTown  1460 non-null   float64\n",
      " 29  Neighborhood_SWISU    1460 non-null   float64\n",
      " 30  Neighborhood_Sawyer   1460 non-null   float64\n",
      " 31  Neighborhood_SawyerW  1460 non-null   float64\n",
      " 32  Neighborhood_Somerst  1460 non-null   float64\n",
      " 33  Neighborhood_StoneBr  1460 non-null   float64\n",
      " 34  Neighborhood_Timber   1460 non-null   float64\n",
      " 35  Neighborhood_Veenker  1460 non-null   float64\n",
      "dtypes: float64(25), int64(11)\n",
      "memory usage: 410.8 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holsson6\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Extract the \"Neighborhood\" column from the DataFrame\n",
    "neighborhood_data = df[['Neighborhood']]\n",
    "\n",
    "# Apply OneHotEncoder to the \"Neighborhood\" column\n",
    "neighborhood_encoded = encoder.fit_transform(neighborhood_data)\n",
    "\n",
    "# Create a DataFrame with the encoded neighborhood data\n",
    "neighborhood_encoded_df = pd.DataFrame(neighborhood_encoded, columns=encoder.get_feature_names_out(['Neighborhood']))\n",
    "\n",
    "# Concatenate the encoded neighborhood DataFrame with the original DataFrame\n",
    "df_encoded = pd.concat([df, neighborhood_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original \"Neighborhood\" column from the DataFrame\n",
    "df_encoded.drop('Neighborhood', axis=1, inplace=True)\n",
    "\n",
    "# Save encoded data to the DataFrame \n",
    "df = df_encoded\n",
    "\n",
    "# Let's see the results\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4770a",
   "metadata": {},
   "source": [
    "### 4. Split data into training and testing sets\n",
    "\n",
    "Now I am ready to split the dataset into training and test data by using the train_test_split function. This function divides the data into training and testing sets based on a specified ratio. The training set will be used to train the model, while the testing set will be used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d13a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df.drop('SalePrice', axis=1)  # Exclude the 'SalePrice' column from features\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1ceae",
   "metadata": {},
   "source": [
    "### 5. Create an instance of the LinearRegression class and fit the model to the training data\n",
    "\n",
    "After splitting the dataset, I instantiate an instance of the LinearRegression class, which represents the linear regression model.\n",
    "\n",
    "Then, I fit the model to the training data using the `fit` method. This step trains the model by finding the best-fitting line that minimizes the difference between the predicted values and the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression model\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0e161",
   "metadata": {},
   "source": [
    "### 6. Make predictions on the testing set\n",
    "\n",
    "Now that the model is trained, I can make predictions on the testing set using the predict method. This step allows me to obtain the predicted values for the target variable based on the features in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06d5c2",
   "metadata": {},
   "source": [
    "### 7. Evaluate the performance of the model using MAE, MSE, and RMSE\n",
    "\n",
    "To evaluate the performance of the model, I calculate two commonly used metrics: mean absolute error (MAE) and mean squared error (MSE). These metrics measure the average absolute difference and the average squared difference, respectively, between the predicted and actual values. I import these metrics from sklearn.metrics and calculate them using the predicted values and the actual values from the testing set.\n",
    "\n",
    "Finally, I may also calculate the root mean squared error (RMSE) by taking the square root of the mean squared error. This metric provides a measure of the average magnitude of the prediction errors in the same units as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c825a",
   "metadata": {},
   "source": [
    "### 8. Analyzing the results\n",
    "\n",
    "#### Mean Absolute Error (MAE):\n",
    "\n",
    "MAE measures the average absolute difference between the predicted and actual values.\n",
    "In this case, the MAE is approximately 19 927.\n",
    "It indicates that, on average, the model's predictions have an absolute difference of around 19 927 units (dollars) from the actual values.\n",
    "A lower MAE value suggests better accuracy, as it represents smaller prediction errors.\n",
    "\n",
    "#### Mean Squared Error (MSE):\n",
    "\n",
    "MSE calculates the average of the squared differences between the predicted and actual values.\n",
    "The MSE value is approximately 1 182 480 620\n",
    "It quantifies the average squared deviation of the model's predictions from the actual values.\n",
    "A lower MSE indicates a better fit, as it represents smaller overall prediction errors.\n",
    "\n",
    "#### Root Mean Squared Error (RMSE):\n",
    "\n",
    "RMSE is the square root of MSE and provides a measure of the average magnitude of the prediction errors.\n",
    "The RMSE value is approximately 34387.\n",
    "It represents the average difference between the predicted and actual values, in the same units as the target variable (dollars).\n",
    "Similar to MAE and MSE, a lower RMSE value indicates better accuracy and a smaller average prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ec85b",
   "metadata": {},
   "source": [
    "### 9. Visualizing the results\n",
    "\n",
    "To get a better understanding of how our model performed, we can plot the data using these plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3383d7",
   "metadata": {},
   "source": [
    "#### Scatter Plot: \n",
    "\n",
    "From a scatter plot, we can observe the relationship between two variables. If the data points form a clear pattern or follow a linear trend, it indicates a strong correlation between the variables. Additionally, we can identify any outliers or clusters in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the sale price\n",
    "plt.scatter(range(len(y_test)), y_test, color='blue', label='Actual Sale Price')\n",
    "# Plotting the predictions\n",
    "plt.scatter(range(len(y_pred)), y_pred, color='red', label='Predicted Sale Price')\n",
    "\n",
    "plt.title('Actual Sale Price vs Predicted Sale Price')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Sale Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7270972",
   "metadata": {},
   "source": [
    "#### Line Plot: \n",
    "\n",
    "A line plot helps us visualize the trend or progression of a variable over time or data points. We can observe whether the variable increases, decreases, or remains relatively constant. It allows us to identify patterns, seasonality, or trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(y_test)), y_test, label='Actual Sale Prices')\n",
    "plt.plot(range(len(y_test)), y_pred, label='Predicted Sale Prices')\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Sale Price')\n",
    "plt.title('Actual vs Predicted Sale Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d0cc3",
   "metadata": {},
   "source": [
    "#### Histogram: \n",
    "\n",
    "By examining a histogram, we can determine the distribution of a single variable. It provides insights into the data's central tendency, spread, and shape. We can identify whether the data is normally distributed, skewed, or exhibits multiple peaks. Outliers or unusual patterns can also be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d389a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test, bins=30, alpha=0.5, label='Actual Sale Prices')\n",
    "plt.hist(y_pred, bins=30, alpha=0.5, label='Predicted Sale Prices')\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Actual and Predicted Sale Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4a25e",
   "metadata": {},
   "source": [
    "#### Box Plot: \n",
    "\n",
    "A box plot summarizes the distribution of a variable and highlights important summary statistics. It allows us to identify the median, quartiles, and potential outliers. We can assess the spread of the data, skewness, and any extreme values that fall beyond the whiskers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([y_test, y_pred], labels=['Actual', 'Predicted'])\n",
    "plt.ylabel('Sale Price')\n",
    "plt.title('Box Plot of Actual and Predicted Sale Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd67e1",
   "metadata": {},
   "source": [
    "#### Residual Plot: \n",
    "\n",
    "Analyzing a residual plot helps us assess the performance of a regression model. We can determine whether the residuals exhibit any patterns or systematic deviations from the expected zero line. It helps us identify potential issues such as heteroscedasticity, non-linearity, or influential outliers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel('Predicted Sale Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032ece1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Your turn\n",
    "\n",
    "Now it's your turn!\n",
    "\n",
    "The required packages are loaded an imported at the start of this document, so you're ready to get started. Your objective is to train a model on the following dataset of Ford cars: [Kaggle.com Ford Car Price Prediction](https://www.kaggle.com/datasets/adhurimquku/ford-car-price-prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afc6d7",
   "metadata": {},
   "source": [
    "### 1. Load and prepare the dataset\n",
    "\n",
    "Load and prepare the dataset by doing the following:\n",
    "\n",
    "- Load the data with `pd.readcsv(...)`\n",
    "- Use `df.info()` and `df.describe()` to explore the dataset.\n",
    "- Select relevant features like I did in my example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb22689",
   "metadata": {},
   "source": [
    "### 2. Encode string data types\n",
    "\n",
    "Now you need to encode some of the data. In my example I used `OneHotEncoder` but you can use `LabelEncoder` instead since there are more columns to encode and more possible values per column. The columns you may want to encode are the columns with the datatype of `object` which you can see by using `df.info()`. THe column called `model` is one of them, but there's two more.\n",
    "\n",
    "To encode the `model` column/attribute you need to:\n",
    "\n",
    "- Initialize LabelEncoder using `LabelEncoder()` and save it to a variable (name it `encoder` for clarity).\n",
    "- Use `encoder.fit_transform(df['model'])` to encode the column. This returns an encoded column which you can save to a new column with any name you'd like. Like this: `df['model_encoded'] = encoder.fit_transform(df['model'])`\n",
    "- Drop the column you encoded from (`model`) by using `df.drop(...)`\n",
    "- Now do the same for the other two columns.\n",
    "\n",
    "When you think you're done, call `df.info()` and make sure all columns are number values such as `int32`, `int64`, or `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476428a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5dd7a6",
   "metadata": {},
   "source": [
    "### 3. Split data into training and testing sets\n",
    "\n",
    "Do just as I did in my example above to split the dataset into features (`X`) and target variable (`y`) and then use `train_test_split(...)` to create training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517fceb",
   "metadata": {},
   "source": [
    "### 4. Create an instance of the LinearRegression class and fit the model to the training data\n",
    "\n",
    "After splitting the dataset, instantiate an instance of the LinearRegression class, which represents the linear regression model.\n",
    "\n",
    "Then fit the model to the training data using the `fit` method. This step trains the model by finding the best-fitting line that minimizes the difference between the predicted values and the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdca406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa5c96",
   "metadata": {},
   "source": [
    "### 5. Make predictions on the testing set\n",
    "\n",
    "Now that the model is trained, you can make predictions on the testing set using the `predict` method. This step lets you obtain the predicted values for the target variable based on the features in the testing set.\n",
    "\n",
    "Print the shape of your predictions to ensure that everything is OK. By calling `print(y_pred.shape)` you should get the result `(3594,)`. This shows you that the predictions is a one dimensional array of 3549 values, which looks right if you split your dataset test data to 20% by setting `test_size=0.2` in the previous step. \n",
    "\n",
    "> **Explanation**: The dataset consist of 17966 rows and by setting `test_size` to 0.2 you split the test data to 20% of all rows, which is about 3593 (`17966 x 0.2 = 3Â 593.2`). If you get a few more or less it's still OK since `train_test_split` will give you a random selection of rows and the exact number may differ because of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a95c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc87cd2",
   "metadata": {},
   "source": [
    "### 6. Evaluate the performance of the model using MAE, MSE, and RMSE\n",
    "\n",
    "- Use `mean_absolute_error(...)` to calculate the Mean Absolute Error (MAE)\n",
    "- Use `mean_squared_error(...)` to calculate the Mean Squared Error (MSE)\n",
    "- Use `sqrt(...)` to calculate the Root Mean Squared Error (RMSE)\n",
    "\n",
    "Print the results when you're done. Compare the results to the mean price and standard deviation of the full dataset (you get these by calling `df['price'].describe()`. Can you draw any conclusions from your results? Is your model good at predicting the prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab5a08",
   "metadata": {},
   "source": [
    "### 7. Visualize the results\n",
    "\n",
    "Follow my examples above to visualize the data using the following plot types:\n",
    "\n",
    "#### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14579fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a9f45",
   "metadata": {},
   "source": [
    "#### Histogram Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce61b2",
   "metadata": {},
   "source": [
    "#### Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b008b86",
   "metadata": {},
   "source": [
    "#### Residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49540271",
   "metadata": {},
   "source": [
    "## Complete!\n",
    "\n",
    "Submit your work by pushing the changes to Github, inviting the teacher/s to your repository and submitting this link on ItsLearning under Assignment 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
